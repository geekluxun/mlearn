{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"/Users/luxun/workspace/ai/mine/codeCopilot/train/local_training.py\")\n",
    "documents = loader.load()\n",
    "# 这里的chunk_size不是字符数，需要理解下 \n",
    "# ai-> CharacterTextSplitter 会按照逻辑结构（例如段落、换行符等）尽量保持原始文档的完整性\n",
    "text_splitter = CharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OllamaEmbeddings(model=\"quentinz/bge-large-zh-v1.5\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "# L2索引 \n",
    "# 存储文档的向量嵌入。\n",
    "# 执行高效的相似性搜索（如 L2 距离）。\n",
    "# 返回的结果是向量索引（数值 ID）\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "#docstore（文档存储）:\n",
    "#存储文档内容和元数据。\n",
    "#将每个文档内容与向量索引关联。\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents, ids=uuids)\n",
    "print(vectorstore)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 持久index\n",
    "faiss.write_index(vector_store.index, \"faiss_index.bin\")\n",
    "\n",
    "# 持久doc 内容\n",
    "import pickle\n",
    "\n",
    "with open(\"vector_store_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"docstore\": vector_store.docstore,\n",
    "        \"index_to_docstore_id\": vector_store.index_to_docstore_id,\n",
    "    }, f)"
   ],
   "id": "9aac9ae262ab6fc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import os\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"quentinz/bge-large-zh-v1.5\")\n",
    "\n",
    "# 1. 加载 FAISS 索引\n",
    "index = faiss.read_index(\"faiss_index.bin\")\n",
    "\n",
    "# 2. 加载文档存储和索引映射\n",
    "with open(\"vector_store_metadata.pkl\", \"rb\") as f:\n",
    "    print(os.path.abspath(f.name))\n",
    "    metadata = pickle.load(f)\n",
    "    docstore = metadata[\"docstore\"]\n",
    "    index_to_docstore_id = metadata[\"index_to_docstore_id\"]\n",
    "\n",
    "# 3. 重建向量存储\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,  # 重新设置嵌入函数\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    ")\n",
    "\n",
    "print(\"Vector store successfully restored!\")\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    #filter={\"source\": \"tweet\"},\n",
    ")\n",
    "# for res in results:\n",
    "#     print(f\"* {res.page_content} [{res.metadata}]\")\n",
    "\n",
    "# 这里的分数为什么为什么会大于0    \n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ],
   "id": "a53ea1ab4a176111",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 查询是否需要归一化\n",
    "print(\"Metric Type:\", vector_store.index.metric_type)\n",
    "print(faiss.METRIC_INNER_PRODUCT, faiss.METRIC_L2)"
   ],
   "id": "bf5784fb1d4eaa8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ],
   "id": "b06c449dd4f1d092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 删除第1个\n",
    "vector_store.delete(ids=[uuids[0]])"
   ],
   "id": "b9afc559d04f4303",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d6f9ea288adeeccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ae7f803ac490e709",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
