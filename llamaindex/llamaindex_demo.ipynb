{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install llama-index llama-index-llms-ollama llama-index-embeddings-huggingface   vector_stores",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install llama-index-vector-stores-milvus",
   "id": "e4714bf71923d367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install nest_asyncio",
   "id": "8db6050b8c8dba11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "2253927dbaa7dd38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "Settings.llm = Ollama(model=\"qwen2.5:7b\", request_timeout=60.0)\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-m3\"\n",
    ")"
   ],
   "id": "ca6519bfd93005dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 构造一个文档\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "document = Document(\n",
    "    text=\"This is a super-customized document\",\n",
    "    metadata={\n",
    "        \"file_name\": \"super_secret_document.txt\",\n",
    "        \"category\": \"finance\",\n",
    "        \"author\": \"LlamaIndex\",\n",
    "    },\n",
    "    excluded_llm_metadata_keys=[\"file_name\"],\n",
    "    metadata_seperator=\"::\",\n",
    "    metadata_template=\"{key}=>{value}\",\n",
    "    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    ")\n",
    "\n",
    "#LLM视角最终读取的内容\n",
    "print(\n",
    "    \"The LLM sees this: \\n\",\n",
    "    document.get_content(metadata_mode=MetadataMode.LLM),\n",
    ")\n",
    "#Embding模型视角最终读取的内容\n",
    "print(\n",
    "    \"The Embedding model sees this: \\n\",\n",
    "    document.get_content(metadata_mode=MetadataMode.EMBED),\n",
    ")"
   ],
   "id": "facd31adf58cebbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 文件索引查询\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(input_dir=\"/Users/luxun/workspace/ai/mine/mlearn/tmp\", recursive=True).load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=Settings.embed_model\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"aiohttp==\")\n",
    "print(response)\n",
    "response = query_engine.query(\"decorator=\")\n",
    "print(response)\n"
   ],
   "id": "5f791be8d40d570b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# db 初始化\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=\"/Users/luxun/workspace/ai/mine/mlearn/tmp/db/milvus.db\", overwrite=False, dim=1024\n",
    ")"
   ],
   "id": "e6f7537f69da233c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pipeline 方式 处理文档\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=25, chunk_overlap=0),\n",
    "        TitleExtractor(),\n",
    "        Settings.embed_model\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# Ingest directly into a vector db\n",
    "pipeline.run(documents=[Document.example()])\n"
   ],
   "id": "ddfc9f7794ad0e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 从DB创建索引和查询\n",
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"LLM\")\n",
    "print(response)"
   ],
   "id": "35c94c2c37e42c1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d92996361632fa80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9d83ff19069c5ab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "20797e613479390d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
