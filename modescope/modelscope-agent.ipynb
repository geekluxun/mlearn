{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from modelscope import snapshot_download\n",
    "\n",
    "model_dir = snapshot_download('qwen/Qwen2-7B-Instruct')\n",
    "print(model_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:22:05.681144Z",
     "start_time": "2024-11-20T08:20:30.155814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ],
   "id": "74da1cab356fe1c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /Users/luxun/.cache/modelscope/hub/Qwen/Qwen2-7B-Instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cdfc7d1ea30475481bb8fb6832f7ff6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /Users/luxun/.cache/modelscope/hub/Qwen/Qwen2-7B-Instruct\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:22:16.946614Z",
     "start_time": "2024-11-20T08:22:16.944715Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "33e1b1868f2a9556",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human-like text. These models are trained on vast amounts of textual data, which allows them to learn the intricacies of language, including syntax, semantics, and context. LLMs can be used for various tasks such as text summarization, question answering, text translation, and creative writing.\n",
      "\n",
      "The most well-known example of an LLM is the GPT (Generative Pre-trained Transformer) series developed by OpenAI, specifically GPT-2 and GPT-3, which have demonstrated impressive abilities in generating coherent and contextually relevant text. Other recent years, Alibaba Cloud has also introduced its own large language models like Qwen, which aims to provide similar capabilities but with unique features and optimizations tailored to Chinese and other Asian languages.\n",
      "\n",
      "These models work by using a technique called \"pre-training\" where they learn from a massive dataset of internet text. This process allows them to understand the patterns and rules of language. After pre-training, they might undergo \"fine-tuning\" on a smaller, more specific dataset to adapt their knowledge to particular particular task or domain.\n",
      "\n",
      "The potential applications of large language models are broad and include customer service chatbots, content generation, text analysis, and even helping in research and development by assisting in writing papers or generating hypotheses. As these models continue to evolve, they promise to become increasingly sophisticated and versatile tools in the field of natural language processing (NLP).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e098be2966fee3db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
